# Hackathon template
A convenient starting template for most deep learning projects. Built with <b>PyTorch Lightning</b> and <b>Weights&Biases</b>.
<br>


## Setup
Read [SETUP.md](SETUP.md)
<br><br>


## Project structure
The directory structure of new project looks like this: 
```
├── project
│   ├── data                    <- Data from third party sources
│   │
│   ├── data_modules            <- Data related modules
│   │   ├── datamodules.py              <- "LightningDataModule" modules
│   │   ├── datasets.py                 <- "Dataset" modules
│   │   └── transforms.py               <- Data transformations (data preprocessing)
│   │
│   ├── logs                    <- Logs generated by Weights&Biases and PyTorch Lightning
│   │
│   ├── utils                   <- Any extra scripts not belonging to training pipeline
│   │
│   ├── notebooks               <- Jupyter notebooks
│   │
│   ├── lightning_modules       <- PyTorch Lightning related modules
│   │   ├── callbacks.py                <- Training callbacks
│   │   └── init_utils.py               <- Some useful initializers
│   │
│   ├── models
│   │   ├── simple_mnist_classifier     <- Example model
│   │   │   ├── lightning_module.py             <- Contains train/val/test step methods
│   │   │   └── models.py                       <- Models declarations used in lightning_module.py
│   │   │
│   │   ├── simple_cifar10_classifier   <- Example model
│   │   │   ├── lightning_module.py             <- Contains train/val/test step methods
│   │   │   └── models.py                       <- Models declarations used in lightning_module.py
│   │   │
│   │   └── ...
│   │
│   ├── project_config.yaml     <- Project configuration
│   ├── run_configs.yaml        <- Different runs configurations
│   ├── execute_sweep.py        <- Special file for executing wandb sweeps (hyperparameter search)
│   └── train.py                <- Train model
│
├── .gitignore
├── LICENSE
├── README.md
├── SETUP.md
├── TIPS.md
└── requirements.txt
```

## Project config parameters 
#### [project_config.yaml](project/project_config.yaml):
```yaml
num_of_gpus: -1

resume_training:
    lightning_ckpt:
        resume_from_ckpt: False
        ckpt_path: "logs/checkpoints/epoch=2.ckpt"
    wandb:
        resume_wandb_run: False
        wandb_run_id: "8uuomodb"

loggers:
    wandb:
        project: "hackathon_template_test"
        team: "kino"
        group: None
        job_type: "train"
        tags: []
        log_model: True
        offline: False

callbacks:
    checkpoint:
        monitor: "val_acc"
        save_top_k: 1
        save_last: True
        mode: "max"
    early_stop:
        monitor: "val_acc"
        patience: 100
        mode: "max"

printing:
    progress_bar_refresh_rate: 5
    weights_summary: "top"  # "full"
    profiler: False
```

## Run config parameters
#### [run_configs.yaml](project/run_configs.yaml):
```yaml
CIFAR10_CLASSIFIER_V2:
    trainer:
        max_epochs: 10
        gradient_clip_val: 0.5
        accumulate_grad_batches: 1
        limit_train_batches: 1.0
    model:
        name: "simple_cifar10_classifier"
        lr: 0.002
        weight_decay: 0.00001
        output_size: 10
        lin1_size: 512
        lin2_size: 256
    dataset:
        name: "CIFAR10DataModule"
        batch_size: 256
        train_val_split_ratio: 0.9
        num_workers: 1
        pin_memory: False
```

## Tips
Read [TIPS.md](TIPS.md)
