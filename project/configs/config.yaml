# @package _global_

# specify here default training configuration
defaults:
    - trainer: default_trainer.yaml
    - model: mnist_model.yaml
    - datamodule: mnist_datamodule.yaml
    - optimizer: adam.yaml
    - seeds: default_seeds.yaml  # set this to null if you don't want to use seeds
    - callbacks: default_callbacks.yaml  # set this to null if you don't want to use callbacks
    - logger: null  # set logger here or use command line (e.g. `python train.py logger=wandb`)


# path to original working directory (the directory that `train.py` was executed from in command line)
# hydra hijacks working directory by changing it to the current log directory,
# so it's useful to have path to original working directory as a special variable
# read more here: https://hydra.cc/docs/next/tutorials/basic/running_your_app/working_directory
original_work_dir: ${hydra:runtime.cwd}


# path to folder with data
data_dir: ${original_work_dir}/data/


# define which things will be saved as hyperparameters by lightning loggers
extra_logs:
    save_model_class_path: True
    save_optimizer_class_path: True
    save_datamodule_class_path: True
    save_model_architecture_class_path: True
    save_model_args: True
    save_datamodule_args: True
    save_optimizer_args: True
    save_trainer_args: False
    save_seeds: True
    save_data_train_val_test_sizes: False


# output paths for hydra logs
hydra:
    run:
        dir: logs/runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    sweep:
        dir: logs/multiruns/${now:%Y-%m-%d_%H-%M-%S}
        subdir: ${hydra.job.num}
