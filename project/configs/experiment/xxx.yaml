# @package _global_
# to execute this experiment run:
# python train.py +experiment=xxx

defaults:
    - override /trainer: default_trainer.yaml
    - override /model: default_classifier.yaml
    - override /datamodule: default_datamodule.yaml
    - override /logger: comet.yaml

pytorch_seed: 12345

trainer:
    args:
        max_epochs: 10

model:
    class: "pytorch_modules.lightning_models.simple_mnist_classifier.LitModel"
    hparams:
        lr: 0.001
        weight_decay: 0.00001
        input_size: 784
        output_size: 10
        lin1_size: 256
        lin2_size: 256
        lin3_size: 128

datamodule:
    class: "pytorch_modules.lightning_datamodules.mnist_datamodule.MNISTDataModule"
    hparams:
        batch_size: 32
        train_val_test_split: [55_000, 5_000, 10_000]
