# set -1 to train on all GPUs abailable, set 0 to train on CPU only
num_of_gpus: -1


# Weights&Biases configuration (just remove this section if you don't want tu use Weights&Biases)
loggers:
    wandb:
        project: "project_template_test"
        entity: "kino"          # change to your username or name of your team on wandb
        log_model: True         # set True to automatically upload model checkpoint to wandb cloud after training
        log_gradients: False    # set True to log gradient histograms (avoid this for very big models)
        offline: False          # set True to store all logs only locally


# default callbacks initialised on every run/experiment
# you can just remove this section or certain callback if you don't want tu use it
# you can add here any callback class available in PyTorch Lightning or template_utils/callbacks.py
# if you specify the same callback class also in run config then it will overwrite the one set here
# all of the callback parameters will be passed to it on initialization
default_callbacks:
    ModelCheckpoint:        # name of PyTorch Lightning class for checkpointing callback
        monitor: "val_acc"      # name of the logged metric which determines when model is improving
        save_top_k: 1           # save k best models (determined by above metric)
        save_last: True         # additionaly always save model from last epoch
        mode: "max"             # can be "max" or "min"
    EarlyStopping:          # name of PyTorch Lightning class for early stopping callback
        monitor: "val_acc"      # name of the logged metric which determines when model is improving
        patience: 5             # how many epochs of not improving until training stops
        mode: "max"             # can be "max" or "min"


# configure things which are printed in terminal
printing:
    progress_bar_refresh_rate: 10   # refresh every 10 batches
    weights_summary: "top"          # print model summary (alternatively "full")
    profiler: False                 # set True to print execution time profiling after training ends


# path to data folder (either absolute or relative to placement of 'train.py' file)
data_dir: "data/"


# path to logs folder (either absolute or relative to placement of 'train.py' file)
logs_dir: "logs/"
