{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972dda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf450d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anno = pd.read_csv(\"../data/eBay/metadata/train.csv\").to_dict()\n",
    "val_anno = pd.read_csv(\"../data/eBay/metadata/val.csv\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = list(train_anno[\"LEAF_CATEG_ID\"].values())\n",
    "val_labels = list(val_anno[\"LEAF_CATEG_ID\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fee8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = list(train_anno[\"IMAGE_PATH\"].values())\n",
    "val_paths = list(val_anno[\"IMAGE_PATH\"].values())\n",
    "paths = train_paths + val_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = list(train_anno[\"AUCT_TITL\"].values())\n",
    "val_texts = list(val_anno[\"AUCT_TITL\"].values())\n",
    "texts = train_texts + val_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d52b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_labels + val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df936090",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92def38",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feats = np.load(\"convnext384_feats.npy\")\n",
    "text_feats = np.load(\"roberta_avg_feats.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958cd077",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_freq = Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_freq.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34225b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = np.where(labels == 941)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529aa10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image_feats = image_feats[class_index]\n",
    "selected_text_feats = text_feats[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ad844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(eps, feats):\n",
    "    cluster = DBSCAN(eps=eps, min_samples=1, metric='cosine', n_jobs=-1)\n",
    "    return cluster.fit_predict(feats)\n",
    "\n",
    "def get_large_cluster(predict_labels, threshold=10):\n",
    "    large_cluster = []\n",
    "    for cluster_label, freq in Counter(predict_labels).most_common():\n",
    "        if freq > threshold:\n",
    "            large_cluster.append(cluster_label)\n",
    "        else:\n",
    "            break\n",
    "    return large_cluster\n",
    "\n",
    "def hierarchical_cluster(maintain_labels, predict_labels, feats, eps=0.5, step=0.1):\n",
    "    large_cluster = get_large_cluster(predict_labels)\n",
    "    for c in large_cluster:\n",
    "        cluster_index = np.where(predict_labels == c)[0]\n",
    "        new_feats = feats[cluster_index]\n",
    "        new_predict_labels = dbscan(eps, new_feats)\n",
    "        new_maintain_labels = [\"\"] * len(cluster_index)\n",
    "        for i, idx in enumerate(cluster_index):\n",
    "            new_maintain_labels[i] += maintain_labels[idx] + \".\" + str(new_predict_labels[i])\n",
    "        if eps > step:\n",
    "            new_maintain_labels = hierarchical_cluster(new_maintain_labels, new_predict_labels, new_feats, eps-step)\n",
    "        for i, idx in enumerate(cluster_index):\n",
    "            maintain_labels[idx] = new_maintain_labels[i]\n",
    "    return maintain_labels\n",
    "    \n",
    "def do_cluster(selected_image_feats, eps=0.5, step=0.1):\n",
    "    predict_labels = dbscan(eps, selected_image_feats)\n",
    "    maintain_labels = [str(x) for x in predict_labels]\n",
    "    maintain_labels = hierarchical_cluster(maintain_labels, predict_labels, selected_image_feats, eps-step)\n",
    "    label_set = set(maintain_labels)\n",
    "    reassign_dict = dict(zip(set(label_set), range(len(label_set))))\n",
    "    predict_labels = [reassign_dict[x] for x in maintain_labels]\n",
    "    return np.array(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels = do_cluster(selected_text_feats, 0.01, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(predict_labels).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predict_label = 1\n",
    "show_index_index = np.where(predict_labels == show_predict_label)[0]\n",
    "show_index = class_index[show_index_index]\n",
    "\n",
    "for idx in show_index[:10]:\n",
    "    print(texts[idx])\n",
    "    image = Image.open(\"../data/eBay/Images/\" + paths[idx])\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d38fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [\"\"] * len(image_feats)\n",
    "for class_name, freq in tqdm(label_freq.most_common()):\n",
    "    class_index = np.where(labels == class_name)[0]\n",
    "    selected_image_feats = image_feats[class_index]\n",
    "    predict_labels = do_cluster(selected_image_feats)\n",
    "    for i, idx in enumerate(class_index):\n",
    "        all_labels[idx] += str(class_name) + \".\" + str(predict_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set(all_labels)\n",
    "reassign_dict = dict(zip(set(label_set), range(len(label_set))))\n",
    "reassign_all_labels = np.array([reassign_dict[x] for x in all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "reassign_all_labels = np.array(list(np.load(\"pseudo_train_ids.npy\")) + list(np.load(\"pseudo_val_ids.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94023830",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(reassign_all_labels).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71226490",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predict_label = 402464\n",
    "show_index = np.where(reassign_all_labels == show_predict_label)[0]\n",
    "\n",
    "for idx in show_index:\n",
    "    print(texts[idx])\n",
    "    image = Image.open(\"../data/eBay/Images/\" + paths[idx])\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73798f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_freq = Counter(reassign_all_labels).most_common()\n",
    "all_freq = [x[1] for x in all_labels_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9892a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(all_freq).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "reassign_train_labels = reassign_all_labels[:len(train_labels)]\n",
    "reassign_val_labels = reassign_all_labels[len(train_labels):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d587a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reassign_train_labels), len(reassign_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6143962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pseudo_train_ids.npy\", reassign_train_labels)\n",
    "np.save(\"pseudo_val_ids.npy\", reassign_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1978dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(reassign_all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e78002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7157da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecbf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for text in tqdm(texts):\n",
    "    text = re.sub('[^\\w|\\d\\.\\d|\\w\\-\\w|\\w/\\w|\\w\\'s]', ' ', text.lower())\n",
    "    text = re.sub('w/', ' ', text)\n",
    "    word_tokens = text.split()\n",
    "    filtered_tokens = [token for token in word_tokens if token not in stop_words]\n",
    "    all_words.extend(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(all_words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726fed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 40\n",
    "filtered_words = []\n",
    "weights = []\n",
    "useless_list = [\"-\", \"w\", \".\"]\n",
    "for x in Counter(all_words).most_common():\n",
    "    if x[1] > threshold:\n",
    "        if x[0] not in useless_list:\n",
    "            filtered_words.append(x[0])\n",
    "            weights.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ef7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a34926",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb693bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(zip(filtered_words, range(len(filtered_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = []\n",
    "for text in tqdm(texts):\n",
    "    text = re.sub('[^\\w|\\d\\.\\d|\\w\\-\\w|\\w/\\w|\\w\\'s]', ' ', text.lower())\n",
    "    text = re.sub('w/', ' ', text)\n",
    "    word_tokens = text.split()\n",
    "    labels = [label_dict[token] for token in word_tokens if token in filtered_words]\n",
    "    new_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb41cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_multi_lables_40.json', 'w') as outfile:\n",
    "    json.dump(new_labels[:len(train_labels)], outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2964fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_multi_lables_40.json', 'w') as outfile:\n",
    "    json.dump(new_labels[len(train_labels):], outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = 22295 / np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76439e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pos_weights.npy\", pos_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2444ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
